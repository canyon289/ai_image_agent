{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Creating a Basic Image Agent\n",
    "\n",
    "![Alt text](img/augLLMs.png)\n",
    "\n",
    "In this tutorial we'll be making a simplified image classifier/agent with Gemma3.\n",
    "\n",
    "Theres two parts\n",
    "\n",
    "* **Multimodal Gemma Classifier** - Using a Gemma model to detect what's in the image and provide a specific output.\n",
    "* **Downstream Action** - A simple function that can process the results of the action, such as sending an email or anything else!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puttting it all together\n",
    "\n",
    "Now that we have an image model ready, let's set up a simple function to interact with the model and its outputs.\n",
    "\n",
    "Let's reedfine `model_call(prompt)` function that sends user input to the LLM and receives a response.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This image shows a **dachshund (wiener dog) dressed up as a hot dog!** \n",
       "\n",
       "The dog is wearing a costume that makes it look like a complete hot dog, complete with a bun and mustard. Itâ€™s a playful and humorous image, often seen in pet costume contests or for a bit of fun."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "import pprint\n",
    "from IPython.display import Markdown\n",
    "\n",
    "image_path = \"img/NotHotDog.jpg\"  # Replace with the actual path to your image file\n",
    "\n",
    "\n",
    "\n",
    "def image_chat(prompt, img_path, model=\"gemma3:27b-it-qat\"):\n",
    "    response = chat(\n",
    "        model = model, \n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': prompt,\n",
    "                'images': [img_path]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response[\"message\"][\"content\"]\n",
    "\n",
    "prompt = \"What is this an image of?\"\n",
    "output = image_chat(prompt, image_path)\n",
    "\n",
    "display(Markdown(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hot Dog or not Hotdog Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"img/NotHotDog.jpg\"  # Replace with the actual path to your image file\n",
    "\n",
    "def image_chat(prompt, img_path, model=\"gemma3:27b-it-qat\"):\n",
    "    response = chat(\n",
    "        model = model, \n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': prompt,\n",
    "                'images': [img_path]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response[\"message\"][\"content\"]\n",
    "\n",
    "prompt = 'Is this an image of the food item hot dog say yes, otherwise say no, no other output'\n",
    "image_chat(prompt, image_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"img/NotHotDog.jpg\"  # Replace with the actual path to your image file\n",
    "\n",
    "def image_chat(prompt, img_path):\n",
    "    response = chat(\n",
    "        model=\"gemma3:27b-it-qat\",  # Use a vision-capable model like LLaVA\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': 'Is this an image of the food item hot dog say yes, otherwise say no, no other output',\n",
    "                'images': [img_path]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response[\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "image_chat(None,image_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the response\n",
    "With our prompt complete we can turn this into a simple classifier. From here you can replace this with any python logic you like, whether its sending an email, or anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"img/Hot_dog_with_mustard.png\"  # Replace with the actual path to your image file\n",
    "\n",
    "image_chat(None, image_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Give treat'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_response(img_path):\n",
    "    response = image_chat(None, image_path)\n",
    "    if response.lower() == 'yes':\n",
    "        return \"Give treat\"\n",
    "    return \"Add ketchup\"\n",
    "\n",
    "parse_response(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Recap: What We Learned \n",
    "\n",
    "In this section, we built our first basic image classification agent that can differentiate between two images and respond accordingly.\n",
    "\n",
    "Here are the key ideas to remember:\n",
    "- **Not everything needs to be chat**: Models can be prompted to return parseable outputs quite easily, no architecture changes needed.\n",
    "- **The model can be an intermediate part of a system**: The model doesn't always need to be front and center of every application.\n",
    "- **From there you can do anything**: We just outputted strings, but with python (or any other language) we can make our system act agentically do anything.\n",
    "\n",
    "This pattern â€” LLM suggests, framework acts â€” is the foundation for building more complex agents later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
